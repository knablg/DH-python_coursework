{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43a4e964-c967-4500-8fe5-0223da4a35af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\lnxin\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.715 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "jieba.load_userdict('customdict.txt')\n",
    "plt.rcParams['font.family'] = 'simhei'\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d48434-dd2f-4d2e-9f6e-edc3c5887789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 基础功能函数\n",
    "def clean_text(text):\n",
    "    # 只保留汉字与标点符号。\n",
    "    text = re.sub(r'[^\\u4e00-\\u9fff。，？、；：（）「」《》“”‘’——……]', '', text)\n",
    "    return text\n",
    "\n",
    "def open_file(fname):\n",
    "    # 接受文件名，返回清洗后的字符串\n",
    "    with open(fname, \"r\",encoding = \"utf-8\", errors = \"ignore\") as f:\n",
    "        text=f.read()\n",
    "    return clean_text(text)\n",
    "\n",
    "def load_stopwords(fname):\n",
    "    stopwords = set()\n",
    "    with open(fname, 'r', encoding = \"utf-8\", errors = \"ignore\") as f:\n",
    "        stopwords.update(line.strip() for line in f if line.strip())\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "def filtered_seg(text):\n",
    "    # 返回词语+词类的元组列表\n",
    "    stopwords = load_stopwords('hit_stopwords.txt')\n",
    "    words = pseg.cut(text)\n",
    "    return [(w, t) for w, t in words if t != 'x' and w not in stopwords]\n",
    "\n",
    "\n",
    "def count(lst):\n",
    "    # 接收列表，返回降序排列的列表\n",
    "    lst = [item for item in lst if item != '' or item !=' ']\n",
    "    count = Counter(lst)\n",
    "    return count.most_common()\n",
    "\n",
    "\n",
    "def bi_gram(lst):\n",
    "    # 二元统计。接受（分词后的）列表，返回二元统计列表 \n",
    "    return [(lst[i],lst[i+1]) for i in range(len(lst)-1)]\n",
    "\n",
    "\n",
    "def tri_gram(lst):\n",
    "    # 三元统计。接受（分词后的）列表，返回三元统计列表\n",
    "    return [(lst[i],lst[i+1],lst[i+2]) for i in range(len(lst)-2)]\n",
    "\n",
    "\n",
    "def plot_top_words(lst, title, xlabel, ylabel, colour, suffix='.png'):\n",
    "    # 接受排序好的以元祖为元素的列表，以条形图的方式可视化，并保存图片\n",
    "    items = [' '.join(x[0]) if isinstance(x[0], tuple) else x[0] for x in lst]\n",
    "    freq = [x[1] for x in lst]\n",
    "    fname = f'{title}{suffix}'\n",
    "    plt.figure(figsize=(10, 6)) \n",
    "    plt.bar(items, freq, align = \"center\", color = colour)\n",
    "    plt.title(title, fontsize=16)\n",
    "    plt.xlabel(xlabel,fontsize=12)\n",
    "    plt.ylabel(ylabel,fontsize=12)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fname, dpi=400)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e97756e-564d-4e3a-9d77-9fbc1049ed7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 整合函数功能\n",
    "def analyse_text(text):\n",
    "    # 对一部作品实现多个指标的统计\n",
    "    words_with_tags = filtered_seg(text)\n",
    "    words = [w for w,t in words_with_tags]\n",
    "    return {\n",
    "        '词语词频列表': count(words),\n",
    "        '二元词频率列表': count(bi_gram(words)),\n",
    "        '三元词频率列表': count(tri_gram(words)),\n",
    "    }\n",
    "\n",
    "\n",
    "def to_file(result:dict, prefix:str, output_dir: str = '词频统计结果'):\n",
    "    # 将analyse_text生成的每项结果写入文件\n",
    "    try: # 确保输出目录存在\n",
    "        os.makedirs(output_dir, exist_ok=True)  # 递归创建目录（如果不存在）\n",
    "    except Exception as e:\n",
    "        print(f'创建输出目录 {output_dir} 时出错：{e}')\n",
    "        return\n",
    "    # 结果写入文件\n",
    "    for name in result:\n",
    "        data = result[name] # 以元组为元素的列表\n",
    "        filename = f'{prefix}_{name}.txt'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        try:\n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                for j,k in data:\n",
    "                    f.write(f'{j},{k}\\n')\n",
    "            print(f'{filename}输出成功')\n",
    "        except Exception as e:\n",
    "            print(f'写入文件 {filename} 时出错：{e}')\n",
    "\n",
    "\n",
    "def plot_all(result, title_prefix):\n",
    "    # 接收analyse_text函数返回的字典，以条形图方式可视化\n",
    "    try:\n",
    "        top_words = result['词语词频列表'][:20]\n",
    "        plot_top_words(top_words, f'{title_prefix}_top20词语','词语','词频',colour='steelblue')\n",
    "        print(f'{title_prefix}_top20词语输出成功')\n",
    "    except Exception as e:\n",
    "        print(f'{title_prefix}:词语词频图失败:{e}')\n",
    "\n",
    "    try:\n",
    "        top_bigram = result['二元词频率列表'][:20]\n",
    "        plot_top_words(top_bigram, f'{title_prefix}_top20二元词语','二元词','词频', colour='mediumseagreen')\n",
    "        print(f'{title_prefix}_top20二元词语输出成功')\n",
    "    except Exception as e:\n",
    "        print(f'{title_prefix}:二元词词频图失败:{e}')\n",
    "\n",
    "    try:\n",
    "        top_trigram = result['三元词频率列表'][:20]\n",
    "        plot_top_words(top_trigram, f'{title_prefix}_top20三元词语','三元词','词频', colour='coral')\n",
    "        print(f'{title_prefix}_top20三元词语输出成功')\n",
    "    except Exception as e:\n",
    "        print(f'{title_prefix}:三元词词频图失败:{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6c6e37-f5a8-4be6-8c6a-76083a7298fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "\u001b[A%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "萧红_1生死场_top20词语输出成功\n",
      "萧红_1生死场_top20二元词语输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|██▌       | 1/4 [00:06<00:20,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "萧红_1生死场_top20三元词语输出成功\n",
      "萧红_1生死场_词语词频列表.txt输出成功\n",
      "萧红_1生死场_二元词频率列表.txt输出成功\n",
      "萧红_1生死场_三元词频率列表.txt输出成功\n",
      "萧红_2呼兰河传_top20词语输出成功\n",
      "萧红_2呼兰河传_top20二元词语输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|█████     | 2/4 [00:16<00:17,  8.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "萧红_2呼兰河传_top20三元词语输出成功\n",
      "萧红_2呼兰河传_词语词频列表.txt输出成功\n",
      "萧红_2呼兰河传_二元词频率列表.txt输出成功\n",
      "萧红_2呼兰河传_三元词频率列表.txt输出成功\n",
      "萧红_3马伯乐_top20词语输出成功\n",
      "萧红_3马伯乐_top20二元词语输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|███████▌  | 3/4 [00:28<00:10, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "萧红_3马伯乐_top20三元词语输出成功\n",
      "萧红_3马伯乐_词语词频列表.txt输出成功\n",
      "萧红_3马伯乐_二元词频率列表.txt输出成功\n",
      "萧红_3马伯乐_三元词频率列表.txt输出成功\n",
      "萧红_4小城三月_top20词语输出成功\n",
      "萧红_4小城三月_top20二元词语输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:31<00:00,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "萧红_4小城三月_top20三元词语输出成功\n",
      "萧红_4小城三月_词语词频列表.txt输出成功\n",
      "萧红_4小城三月_二元词频率列表.txt输出成功\n",
      "萧红_4小城三月_三元词频率列表.txt输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "萧红_all_works_top20词语输出成功\n",
      "萧红_all_works_top20二元词语输出成功\n",
      "萧红_all_works_top20三元词语输出成功\n",
      "萧红_all_works_词语词频列表.txt输出成功\n",
      "萧红_all_works_二元词频率列表.txt输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:56<00:56, 56.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "萧红_all_works_三元词频率列表.txt输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丁玲_1韦护_top20词语输出成功\n",
      "丁玲_1韦护_top20二元词语输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|██▌       | 1/4 [00:07<00:21,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丁玲_1韦护_top20三元词语输出成功\n",
      "丁玲_1韦护_词语词频列表.txt输出成功\n",
      "丁玲_1韦护_二元词频率列表.txt输出成功\n",
      "丁玲_1韦护_三元词频率列表.txt输出成功\n",
      "丁玲_2一九三零_top20词语输出成功\n",
      "丁玲_2一九三零_top20二元词语输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|█████     | 2/4 [00:12<00:12,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丁玲_2一九三零_top20三元词语输出成功\n",
      "丁玲_2一九三零_词语词频列表.txt输出成功\n",
      "丁玲_2一九三零_二元词频率列表.txt输出成功\n",
      "丁玲_2一九三零_三元词频率列表.txt输出成功\n",
      "丁玲_3母亲_top20词语输出成功\n",
      "丁玲_3母亲_top20二元词语输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A%|███████▌  | 3/4 [00:20<00:06,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丁玲_3母亲_top20三元词语输出成功\n",
      "丁玲_3母亲_词语词频列表.txt输出成功\n",
      "丁玲_3母亲_二元词频率列表.txt输出成功\n",
      "丁玲_3母亲_三元词频率列表.txt输出成功\n",
      "丁玲_4桑干河_top20词语输出成功\n",
      "丁玲_4桑干河_top20二元词语输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:34<00:00,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丁玲_4桑干河_top20三元词语输出成功\n",
      "丁玲_4桑干河_词语词频列表.txt输出成功\n",
      "丁玲_4桑干河_二元词频率列表.txt输出成功\n",
      "丁玲_4桑干河_三元词频率列表.txt输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丁玲_all_works_top20词语输出成功\n",
      "丁玲_all_works_top20二元词语输出成功\n",
      "丁玲_all_works_top20三元词语输出成功\n",
      "丁玲_all_works_词语词频列表.txt输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:57<00:00, 59.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "丁玲_all_works_二元词频率列表.txt输出成功\n",
      "丁玲_all_works_三元词频率列表.txt输出成功\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:57<00:00, 58.94s/it]\n"
     ]
    }
   ],
   "source": [
    "# 在此指定需要分析的作者及作品\n",
    "authors = {'萧红':['生死场.txt','呼兰河传.txt','马伯乐.txt','小城三月.txt'],\n",
    "           '丁玲':['韦护.txt','一九三零.txt','母亲.txt','桑干河.txt']\n",
    "}\n",
    "\n",
    "\n",
    "def main():\n",
    "    for author, works in tqdm(authors.items()):\n",
    "        all_text = ''\n",
    "        \n",
    "        # 以作品为单位的统计\n",
    "        for filepath in tqdm(works):\n",
    "            try:\n",
    "                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                    text = clean_text(f.read())\n",
    "                all_text += text + '\\n'  # 合并所有作品文本\n",
    "\n",
    "                # 统计单个作品、可视化输出\n",
    "                result = analyse_text(text)\n",
    "                fname = f'{author}_{filepath[:-4]}'\n",
    "                plot_all(result, title_prefix=fname)\n",
    "                to_file(result, fname)\n",
    "            except Exception as e:\n",
    "                print(f'处理作品 {filepath} 时出错：{e}')\n",
    "\n",
    "        # 以作家为单位的统计\n",
    "        try: \n",
    "            result_all = analyse_text(all_text)\n",
    "            fname_all = f'{author}_all_works'\n",
    "            plot_all(result_all, title_prefix=fname_all)\n",
    "            to_file(result_all, fname_all)\n",
    "        except Exception as e:\n",
    "            print(f'写入作家{author}的统计文件时出错：{e}')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac64abe-47ee-4bf2-a6b7-1b46128eef17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pkuseg",
   "language": "python",
   "name": "pkuseg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
